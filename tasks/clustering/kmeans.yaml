title: Kmeans implementieren
question: |
  Implementieren Sie das KMeans Model, sodass es sich in die sklearn Modelle einbettet.
solution: |
  ```python
  ### Henrik
  
  from sklearn.base import BaseEstimator, ClusterMixin
  import numpy as np
  import matplotlib.pyplot as plt
  import random
  
  class MyKMeans(BaseEstimator, ClusterMixin):
      def __init__(self, n_clusters: int, max_iter:int=300, tol:float=0.0001, init='random', random_state:int=None, max_epochs:int=20):
          super().__init__()
          self.n_cluster:int = n_clusters
          self.max_iter:int = max_iter
          self.tol:float = tol
          self.init = init
          self.random_state:int = random_state
          self.max_epochs:int = max_epochs
          self.labels_:np.ndarray = None
          self.cluster_centers_:np.ndarray = None
          self.inertia_:float = None
          
       
      def _create_starting_centers(self, X:np.ndarray):
          if isinstance(self.init, np.ndarray):
              if self.init.shape == (self.n_cluster, X.shape[1]):
                  return self.init
              else:
                  raise ValueError(
                      f"Error: self.init hat die falsche Form {self.init.shape}, erwartet wurde {(self.n_cluster, X.shape[1])}."
                  )
          elif isinstance(self.init, str):
              if self.init == 'random':
                  np.random.seed(self.random_state)
                  min_values = np.min(X, axis=0)
                  max_values = np.max(X, axis=0)
                  return np.random.uniform(min_values, max_values, size=(self.n_cluster, X.shape[1])) 
              else:
                  raise ValueError(
                      f"Error: self.init kann nur ein string 'random' oder ein ndarray sein"
                  )
          else:
              raise TypeError(
                  f"Error: self.init muss entweder 'random' oder ein NumPy-Array sein, aber ist {type(self.init)}."
              )
  
         
      def _calc_dist(self, X, centers):
          return np.sum((X[:, np.newaxis, :] - centers[np.newaxis, :, :]) ** 2, axis=2)
      
      def _assign_labels(self, dist): 
          return np.argmin(dist, axis=1)
          
      def _calc_inertia(self, dist, labels):
          return np.sum(dist[np.arange(len(labels)), labels])
          
      def _new_cluster_centers(self, X, labels:np.ndarray, old_centers: np.ndarray):
          new_centers = []
          for i in range(self.n_cluster):
              if np.any(labels == i): 
                  new_centers.append(X[labels == i].mean(axis=0))
              else:
                  new_centers.append(old_centers[i])
          return np.array(new_centers)
    
      def fit(self, X, show=False):
          epoch_labels = []
          epoch_cluster_centers = []
          epoch_inertia = []
          for i in range(self.max_epochs):
              centers = self._create_starting_centers(X)
              old_inertia = float("inf")
              labels = None
              for n in range(self.max_iter):
                  if labels is not None:
                      centers = self._new_cluster_centers(X, labels, centers)
                  dist = self._calc_dist(X, centers)
                  labels = self._assign_labels(dist)
                  new_inertia = np.sum(self._calc_inertia(dist, labels))
                  if np.isclose(new_inertia, old_inertia):
                      epoch_labels.append(labels)
                      epoch_cluster_centers.append(centers)
                      epoch_inertia.append(new_inertia)
                      break
                  old_inertia = new_inertia
                  if show:
                      self.show_labels(X, labels, centers)
              else:
                  epoch_labels.append(labels)
                  epoch_cluster_centers.append(centers)
                  epoch_inertia.append(new_inertia)
          best_index = np.argmin(epoch_inertia)
          self.labels_ = epoch_labels[best_index]
          self.cluster_centers_ = epoch_cluster_centers[best_index]
          self.inertia_ = epoch_inertia[best_index]
          return self.labels_, self.cluster_centers_, self.inertia_
      
      def predict(self, X):
          dist = self._calc_dist(X, self.cluster_centers_)
          return self._assign_labels(dist)
      
      def show_labels(self, X, labels, centers):
          plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', edgecolors='k', s=100)
          plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x', s=200, label="Cluster-Zentren")
          plt.show()
  
  def create_cluster_array(random_seed:int=42) -> np.array:
      np.random.seed(random_seed)
      cluster_1 = np.random.randn(50, 2) * 0.5 + [2, 2]
      cluster_2 = np.random.randn(50, 2) * 2 + [4, 4]
      cluster_3 = np.random.randn(50, 2) * 0.5 + [2, 6]
      cluster_4 = np.random.randn(50, 2) * 0.5 + [6, 2]
      return np.vstack((cluster_1, cluster_2, cluster_3, cluster_4))
  
  def show_labels(X, labels, centers):
      plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', edgecolors='k', s=100)
      plt.scatter(centers[:, 0], centers[:, 1], c='red', marker='x', s=200, label="Cluster-Zentren")
      plt.show()
       
  if __name__ == "__main__":
      data = create_cluster_array()
      model = MyKMeans(n_clusters=4, random_state=None, init="random", max_epochs=50)
      labels, center, inertia = model.fit(data, show=False)
      print(model.predict(X=np.array([[0,0]])), center)
      show_labels(data, labels, center)
      
  
  import matplotlib.pyplot as plt
  import numpy as np
  import random
  from sklearn.base import BaseEstimator, ClusterMixin
  from PIL import Image
  
  def euclid_squared(x, c):
      return np.sum((x - c) ** 2)
  
  class MyKMean(BaseEstimator, ClusterMixin):
      def __init__(self, n_cluster, max_iter=300, tol=0.0001, init='random', random_state=None, dist=euclid_squared):
          self.n_cluster = n_cluster
          self.random_state = random_state
          self.max_iter = max_iter
          self.tol = tol
          self.dist = dist
          self.init = init
  
      def fit(self, X, y=None, visualize=False):
          # Centroids initialisieren
          if not isinstance(self.init, np.ndarray):
              X = np.array(X)
              min_x = np.min(X, axis=0)
              max_x = np.max(X, axis=0)
              random.seed(self.random_state)
              C_start = {tuple(min_x + random.random() * (max_x - min_x)): [] for _ in range(self.n_cluster)}
          else:
              C_start = {i: [] for i in self.init}
  
          # Zuordnen der Daten aus X zu dem jeweils nächstem Centroid
          for x in X:
              closest_cluster = min(C_start.keys(), key=lambda c: self.dist(x, np.array(c)))
              C_start[closest_cluster].append(x)
  
          # Vor dem Schelifenbeginn merker für vorhrerige Toleranz und aktuelle toleranz und Durchlaufzähler initialisieren
          prev_tol = 0
          act_tol = None
          i = 0
  
          if visualize:
              fig, ax = plt.subplots()
          # Hauptschleife, die solange durchlaufen wird bis Terminierungsbedingungen erfüllt sind
          while (act_tol is None or act_tol > self.tol) and i < self.max_iter:
  
              i += 1
              # Neue optimierte Centroids berechnen
              new_C = {}
              for c in C_start.keys():
                  if C_start[c]:
                      new_C[tuple(np.mean(C_start[c], axis=0))] = []
                  else:
                      new_C[c] = []
              # Punkte dem neuen Centroid zuordnen
              for x in X:
                  closest_cluster = min(new_C.keys(), key=lambda c: self.dist(x, np.array(c)))
                  new_C[closest_cluster].append(x)
  
              # Inertia berechnen 
              inertia = sum(self.dist(x, np.array(c)) for c in new_C.keys() for x in new_C[c])
              # Inertia speichern und aktuelle Toleranz ermittlen
              if act_tol is not None:
                  prev_tol = act_tol
              act_tol = abs(inertia - prev_tol)
  
              C_start = new_C
  
              if visualize:
                  ax.clear()
                  colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']
                  for idx, (cluster, points) in enumerate(C_start.items()):
                      points = np.array(points)
                      ax.scatter(points[:, 0], points[:, 1], c=colors[idx % len(colors)], label=f'Cluster {idx}')
                  centers = np.array(list(C_start.keys()))
                  ax.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X', label='Centers')
                  ax.legend()
                  plt.draw()
                  plt.pause(0.5)
  
          if visualize:
              plt.show()
  
          self.cluster_centers_ = list(C_start.keys())
          self.labels_ = [min(self.cluster_centers_, key=lambda c: self.dist(x, np.array(c))) for x in X]
  
      def predict(self, X):
          return [min(self.cluster_centers_, key=lambda c: self.dist(x, np.array(c))) for x in X]
  
  def image_seg(image_path, n_clusters=3):
      image_org = Image.open(image_path)
      image_np = np.array(image_org)
  
      # Reshape the image to a 2D array of pixels
      pixels = image_np.reshape(-1, 3)
  
      # Apply KMeans clustering to segment the image
      kmeans = MyKMean(n_cluster=n_clusters, random_state=42)
      kmeans.fit(pixels)
  
      # Replace each pixel value with its corresponding cluster center value
      segmented_img_np = np.array([kmeans.cluster_centers_[label] for label in kmeans.labels_])
      segmented_img_np = segmented_img_np.reshape(image_np.shape).astype(np.uint8)
  
      # Convert the numpy array back to an image
      segmented_img = Image.fromarray(segmented_img_np)
  
      return segmented_img
  
  # Beispiel-Daten
  X = np.random.rand(100, 2)
  kmeans = MyKMean(n_cluster=3, random_state=42)
  kmeans.fit(X, visualize=False)
  
  X = np.random.rand(100, 3)
  kmean_2 = MyKMean(n_cluster=3, random_state=42)
  kmean_2.fit(X)
  # Beispiel-Daten
  X = np.random.rand(100, 2)
  kmeans = MyKMean(n_cluster=3, random_state=42)
  kmeans.fit(X, visualize=True)
  
  -----------Johannes/Andi--------
  
  
  def euclidean_distances(X, centroids):
      return np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)
  
  def axis_aligned_distances(X, centroids):
      return np.abs(X[:, np.newaxis] - centroids).sum(axis=2)  # Manhattan-Distanz
  
  def kmeans_with_plots(X, k, max_iters=10, tol=1e-4, distance_func=euclidean_distances, random_state = 42):
      np.random.seed(random_state)  # Für Reproduzierbarkeit
      n_samples, n_features = X.shape
      
      # Zufällige Auswahl der Start-Centroids
      centroids = X[np.random.choice(n_samples, k, replace=False)]
      
      # Subplots vorbereiten
      fig, axes = plt.subplots(2, 5, figsize=(20, 8))  # 2 Zeilen, 5 Spalten
      axes = axes.flatten()  # 2D -> 1D Array für leichtere Iteration
      
      for i in range(max_iters):
          # Schritt 1: Cluster-Zuordnung mit externer Distanzfunktion
          distances = distance_func(X, centroids)
          labels = np.argmin(distances, axis=1)
          
          # Schritt 2: Neue Centroids berechnen
          new_centroids = np.array([X[labels == j].mean(axis=0) if np.any(labels == j) else centroids[j] for j in range(k)])
          
          # Plot der aktuellen Iteration
          ax = axes[i]  # Aktuelles Subplot
          ax.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6)
          ax.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label='Centroids')
          
          # Linien von Punkten zu den Centroids zeichnen
          for j in range(n_samples):
              ax.plot([X[j, 0], centroids[labels[j], 0]], [X[j, 1], centroids[labels[j], 1]], 'k-', alpha=0.2)
  
          ax.set_title(f"Iteration {i+1}")
          
          # Konvergenzprüfung
          if np.linalg.norm(new_centroids - centroids) < tol:
              break
  
          centroids = new_centroids
  
      plt.tight_layout()
      plt.show()
      
      
      
  X, _ = make_blobs(n_samples=300, centers=8, cluster_std=2, random_state=42)  # Erhöhte Streuung
  
  # K-Means mit Visualisierung aufrufen
  kmeans_with_plots(X, k=3, distance_func=axis_aligned_distances)
  
    
    
    
  if __name__ == '__main__':
      unittest.main(argv=[''], exit=False)
  ```
